I want to build a deep research system, where a large model writes python programs that define how a small model crawls a very long context. You can look at example implementations in Users/williamjurayj/Documents/2026/rlm, /Users/williamjurayj/Documents/2026/agentic-information-theory/src/ib/pipeline, and /Users/williamjurayj/Documents/2026/agentic-information-theory/src/deepresearch/res_swarm/src/deepres_minion.py for example implementations. However, these are all substantially developed projects, whereas I want to do greenfield development on a minimal implementation, to implement the idea described in idea.md. Read and reflect on these projects, and help me plan how you will implement it.